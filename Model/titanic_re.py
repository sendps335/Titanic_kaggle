# -*- coding: utf-8 -*-
"""Titanic re.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vxGc9FC5-6NVzilYTlXRtNFm1UgB_LPm
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

df=pd.read_csv('train.csv')
df1=pd.read_csv('test.csv')

df.drop('PassengerId',axis=1,inplace=True)
df1.drop('PassengerId',axis=1,inplace=True)

df1.isnull().sum()

df1['Age'].fillna(df1.Age.median(), inplace=True)

df['Age'].fillna(df.Age.median(), inplace=True)

df1['Fare'].fillna(df1.Fare.median(), inplace=True)

df['Embarked'].fillna('C',inplace=True)

df1.isnull().sum()

df['Cabin'+'_NA'] = np.where(df['Cabin'].isnull(), 1, 0)

df1['Cabin'+'_NA'] = np.where(df1['Cabin'].isnull(), 1, 0)

# selecting random sample for filling the na values
random_sample = df['Cabin'].dropna().sample(df['Cabin'].isnull().sum(), random_state=0,replace=True)

# pandas needs to have the same index in order to merge datasets
random_sample.index = df[df['Cabin'].isnull()].index

# map the random sample to fill in the null values

df.loc[df['Cabin'].isnull(), 'Cabin'] = random_sample

# selecting random sample for filling the na values
random_sample = df1['Cabin'].dropna().sample(df1['Cabin'].isnull().sum(), random_state=0,replace=True)

# pandas needs to have the same index in order to merge datasets
random_sample.index = df1[df1['Cabin'].isnull()].index

# map the random sample to fill in the null values

df1.loc[df1['Cabin'].isnull(), 'Cabin'] = random_sample



df1['Cabin'] = df1['Cabin'].astype(str).str[0]

df['Cabin'] = df['Cabin'].astype(str).str[0]

df1.Cabin.unique()

import re

df['Title'] = df.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\.', x).group(1))

df1['Title'] = df1.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\.', x).group(1))

df['Title'] = df['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})
df['Title'] = df['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',
                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Rare')

import seaborn as sns

sns.countplot(x='Title', data=df1);
plt.xticks(rotation=45);

df1['Title'] = df1['Title'].replace({'Ms':'Miss'})
df1['Title'] = df1['Title'].replace(['Dona', 'Rev', 'Dr',
                                            'Col'],'Rare')

for col in ['Sex', 'Cabin', 'Title','Embarked']:
    labels_dict = {k:i for i, k in enumerate(df[col].unique(), 0)}
    df1[col]=df1[col].map(labels_dict)

for col in ['Sex', 'Cabin', 'Title','Embarked']:
    labels_dict = {k:i for i, k in enumerate(df[col].unique(), 0)}
    df[col]=df[col].map(labels_dict)

df.head()

df.drop(['Name','Ticket'],axis=1,inplace=True)
df1.drop(['Name','Ticket'],axis=1,inplace=True)

df.head()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df.drop('Survived',axis=1), df['Survived'], test_size=0.33, random_state=42)

logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)

from sklearn.metrics import classification_report

predictions = logmodel.predict(X_test)

print(classification_report(y_test,predictions))



pred=logmodel.predict(df1)



ss=pd.read_csv('test.csv')
ids = ss['PassengerId'].values

submission_file = open("submission2.csv", "w")

import csv as csv

open_file_object = csv.writer(submission_file)

# Write the header of the csv
open_file_object.writerow(["Id","SalePrice"])

# Write the rows of the csv
open_file_object.writerows(zip(ids, pred))

# Close the file
submission_file.close()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import xgboost as xgb

data_dmatrix = xgb.DMatrix(data=df.drop('Survived',axis=1),label=df.Survived)

#params = {"objective":"reg:logistic", "max_depth":3,"colsample_bytree": 0.7,"gamma": 0.5,"learning_rate": 0.01,"lambda": 1,"reg_alpha": 0.1}

# Perform cross-validation: cv_results
#cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3, num_boost_round=5, metrics="error", as_pandas= True, seed=123)

from sklearn.model_selection import RandomizedSearchCV
import numpy as np
gbm_param_grid = {
    'n_estimators': range(1,500),
    'max_depth': range(2, 20),
    "colsample_bytree": np.linspace(0,1,10),
    "gamma": np.linspace(0,1,10),
    "learning_rate": np.linspace(0,0.05,10),
    "lambda": np.linspace(0,1,10),
    "reg_alpha": np.linspace(0,1,10)
}

gbm= xgb.XGBClassifier(n_estimators=10)
randomized_mse = RandomizedSearchCV(estimator=gbm,param_distributions=gbm_param_grid,scoring='neg_mean_squared_error',n_iter=5,cv=3,verbose=1)

randomized_mse.fit(df.drop('Survived',axis=1),df['Survived'])

randomized_mse.best_params_



xg_cl = xgb.XGBClassifier( objective='binary:logistic',max_depth=13,colsample_bytree = 0.4444444444444444,gamma = 1,learning_rate= 0.03333333333333333,reg_lambda= 0.7777777777777777,reg_alpha=0.6666666666666666,n_estimators=227, seed=123)

xg_cl.fit(X_train,y_train)

preds=xg_cl.predict(X_test)

print(classification_report(y_test,preds))

preds=xg_cl.predict(df1)

ss=pd.read_csv('test.csv')
ids = ss['PassengerId'].values

submission_file = open("submission2.csv", "w")

import csv as csv

open_file_object = csv.writer(submission_file)

# Write the header of the csv
open_file_object.writerow(["PassengerId","Survived"])

# Write the rows of the csv
open_file_object.writerows(zip(ids, preds))

# Close the file
submission_file.close()

